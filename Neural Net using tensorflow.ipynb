{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,f1_score,recall_score,precision_score,accuracy_score,precision_recall_curve,roc_curve,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 29)\n",
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"/home/hr/Documents/creditcard.csv\")\n",
    "dataset1 = dataset.ix[:,1:-1]\n",
    "print(dataset1.shape)\n",
    "print(dataset.shape)\n",
    "X = dataset.iloc[:,1:-1]\n",
    "Y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalanceCascade\n",
    "from imblearn.tensorflow import balanced_batch_generator\n",
    "from imblearn.datasets import make_imbalance\n",
    "class_dict = dict()\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X1, y1 = make_imbalance(X, Y, class_dict)\n",
    "X1 = X1.astype(np.float32)\n",
    "batch_size, learning_rate, epochs = 10000, 0.01, 20\n",
    "training_generator, steps_per_epoch = balanced_batch_generator(X1, y1, sample_weight=None, sampler=None,\n",
    "                                                               batch_size=batch_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(np.argmax(y_pred, axis=1) == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "epoch: 0 train accuracy: 0.968 \n",
      "epoch: 1 train accuracy: 0.968 \n",
      "epoch: 2 train accuracy: 0.968 \n",
      "epoch: 3 train accuracy: 0.968 \n",
      "epoch: 4 train accuracy: 0.968 \n",
      "epoch: 5 train accuracy: 0.968 \n",
      "epoch: 6 train accuracy: 0.968 \n",
      "epoch: 7 train accuracy: 0.968 \n",
      "epoch: 8 train accuracy: 0.968 \n",
      "epoch: 9 train accuracy: 0.968 \n",
      "epoch: 10 train accuracy: 0.968 \n",
      "epoch: 11 train accuracy: 0.968 \n",
      "epoch: 12 train accuracy: 0.968 \n",
      "epoch: 13 train accuracy: 0.968 \n",
      "epoch: 14 train accuracy: 0.968 \n",
      "epoch: 15 train accuracy: 0.968 \n",
      "epoch: 16 train accuracy: 0.968 \n",
      "epoch: 17 train accuracy: 0.968 \n",
      "epoch: 18 train accuracy: 0.968 \n",
      "epoch: 19 train accuracy: 0.968 \n"
     ]
    }
   ],
   "source": [
    "input_size, output_size = X1.shape[1], 2\n",
    "data = tf.placeholder(\"float32\", shape=[None, input_size])\n",
    "targets = tf.placeholder(\"int32\", shape=[None])\n",
    "# build the model and weights\n",
    "W = init_weights([input_size, output_size])\n",
    "b = init_weights([output_size])\n",
    "out_act = tf.nn.sigmoid(tf.matmul(data, W) + b)\n",
    "# build the loss, predict, and train operator\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=out_act, labels=targets)\n",
    "loss = tf.reduce_sum(cross_entropy)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "predict = tf.nn.softmax(out_act)\n",
    "# Initialization of all variables in the graph\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    print('Starting training')\n",
    "    sess.run(init)\n",
    "    for e in range(epochs):\n",
    "        for i in range(steps_per_epoch):\n",
    "            X_batch, y_batch = next(training_generator)\n",
    "            feed_dict = dict()\n",
    "            feed_dict[data] = X_batch; feed_dict[targets] = y_batch\n",
    "            sess.run([train_op, loss], feed_dict=feed_dict)\n",
    "            # For each epoch, run accuracy on train and test\n",
    "        feed_dict = dict()\n",
    "        feed_dict[data] = X1\n",
    "        predicts_train = sess.run(predict, feed_dict=feed_dict)\n",
    "        print(\"epoch: {} train accuracy: {:.3f} \" .format(e, accuracy(y1, predicts_train)))\n",
    "            # doctest: +ELLIPSIS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
